$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json

# name of the experiment, use this to structure your training results
experiment_name: pl-deepspeed

# several input parameters for your training job
inputs:
    # name of the model, ensure that there is a corresponding Python script in folder 'models'
    model: ImageClassifier

    # name of the data module
    data_module: MNIST

    # training strategy used by Lightning
    # - see https://pytorch-lightning.readthedocs.io/en/stable/extensions/strategy.html#id1 to get an idea of the
    #   available strategies
    # - for a full list of available strategies, run python train.py --help
    training_strategy: deepspeed

    # maximum number of epochs
    max_epochs: 100

# compute cluster on which the command above should be run
# note: before you can use the compute, it needs to be created first in your AzureML workspace
compute: multi-node-multi-gpu-lp

# compute resources
resources:
    # number of nodes in the cluster above
    instance_count: 2

# communication between nodes
distribution:
    # when distribution type "pytorch" is used, AML will set up everything required for distributed training of PyTorch 
    # models, for example the NCCL backend
    type: pytorch

    # IMPORTANT: set this value to the number of GPUs per device (depends on your VM size)
    process_count_per_instance: 2

# environment in which the command above should be run in
# note: It is recommended to use an environment which either is the ACPT image or at least inherits from it. The ACPT
#       image has many frameworks related to PyTorch pre-installed, hence reduces efforts to create your own
#       environment. To learn more about environments in AML, see
#       https://learn.microsoft.com/en-us/azure/machine-learning/concept-environments
#
# for the latest ACPT image using PyTorch 1.12, CUDA 11.6 on Python 3.9
environment: azureml:AzureML-ACPT-pytorch-1.12-py39-cuda11.6-gpu@latest
# for a specific version
#environment: azureml:AzureML-ACPT-pytorch-1.12-py39-cuda11.6-gpu:3
# for the latest version of a custom environment:
#environment: azureml:ACPT-Extended@latest
# for a specific Docker image (has to be compatible with Azure ML):
#environment:
#    image: mcr.microsoft.com/azureml/curated/acpt-pytorch-1.12-py39-cuda11.6-gpu:2

# command that should be run by the job
command: |
    python train.py \
        --model ${{inputs.model}} \
        --data-module ${{inputs.data_module}} \
        --training-strategy ${{inputs.training_strategy}} \
        --max-epochs ${{inputs.max_epochs}}

# local directory that contains the code for the job
# note: By default, all contents of the specified directory are uploaded to Azure ML. If you want to avoid that specific
#       files or folders are uploaded, add an .amlignore file to that directory. Contents and syntax is the same as with
#       .gitignore files.
code: .

# TODO: update
# # optional: side services
# # - the services defined here are services running in parallel to the job
# # - for more details, see https://learn.microsoft.com/en-us/azure/machine-learning/how-to-interactive-jobs
# # - feature is still in preview, hence might not work as expected in certain situations
# services:
#     my_vs_code:
#         job_service_type: vs_code
#         nodes: all
#     my_tensor_board:
#         job_service_type: tensor_board
#         properties:
#             logDir: "outputs"
#         nodes: all
#     my_jupyter_lab:
#         job_service_type: jupyter_lab
#         nodes: all
#     my_ssh:
#         job_service_type: ssh
#         properties:
#             sshPublicKeys: <paste the entire pub key content>
#         nodes: all
